model:
  # EnCodec model configuration
  sample_rate: 16000  # As per dataset.py
  hop_length: 256    # As per dataset.py
  latent_dim: 128
  channels:
    - 128
    - 256
    - 384
    - 512
  strides:
    - 2
    - 2
    - 2
    - 2
  kernel_size: 7
  dilation_rates:
    - 1
    - 3
    - 9

# RVQ configuration
quantizer:
  num_codebooks: 4
  vectors_per_codebook: 1024
  commitment_weight: 0.25
  use_commitment_loss: true  # Can be turned off

# Loss weights
losses:
  reconstruction_weight: 1.0
  use_phoneme_alignment: true  # Can be turned off
  phoneme_alignment_weight: 0.5

# Training configuration
training:
  batch_size: 16
  learning_rate: 3.0e-4
  num_workers: 4
  max_epochs: 1000
  log_every_n_steps: 100
  val_check_interval: 0.25  # 25% of an epoch
  precision: 16
  
# Logging configuration
logging:
  log_audio_every_n_epochs: 5
  num_audio_samples: 1  # Number of samples to log
  visualize_embeddings: true
  log_dir: "logs"